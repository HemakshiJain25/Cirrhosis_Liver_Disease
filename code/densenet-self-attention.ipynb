{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11088663,"sourceType":"datasetVersion","datasetId":6911699}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nnp.random.seed(42) \nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models, transforms, datasets\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchsummary import summary","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_classes = len(os.listdir('/kaggle/input/liver-diseases-dataset/Liver Disease Dataset/train'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Custom Dataset Class\n\n\nclass LiverDiseaseDataset(Dataset):\n    def __init__(self, data, transform=None):\n        self.data = data\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        image_path, _, label = self.data[idx]\n        image = Image.open(image_path).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        label_idx = class_names.index(label)  # Convert label to index\n        return image, label_idx\n\n# Get Class Names from Train Directory\nclass_names = os.listdir('/kaggle/input/liver-diseases-dataset/Liver Disease Dataset/train')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dir = '/kaggle/input/liver-diseases-dataset/Liver Disease Dataset/train'\ntraining_data = []\n\nfor label in os.listdir(train_dir):\n    label_dir = os.path.join(train_dir,label)\n    for patient in os.listdir(label_dir):\n        patient_dir = os.path.join(label_dir, patient)\n        images_dir = os.path.join(patient_dir, 'images')\n\n        for filename in os.listdir(images_dir):\n            image_path = os.path.join(images_dir, filename)\n            training_data.append([image_path, patient, label])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dir = '/kaggle/input/liver-diseases-dataset/Liver Disease Dataset/test'\ntesting_data = []\n\nfor label in os.listdir(test_dir):\n    label_dir = os.path.join(test_dir,label)\n    for patient in os.listdir(label_dir):\n        patient_dir = os.path.join(label_dir, patient)\n        images_dir = os.path.join(patient_dir, 'images')\n\n        for filename in os.listdir(images_dir):\n            image_path = os.path.join(images_dir, filename)\n            testing_data.append([image_path, patient, label])\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"valid_dir = '/kaggle/input/liver-diseases-dataset/Liver Disease Dataset/test'\nvalidation_data = []\n\nfor label in os.listdir(valid_dir):\n    label_dir = os.path.join(test_dir,label)\n    for patient in os.listdir(label_dir):\n        patient_dir = os.path.join(label_dir, patient)\n        valid_dir = os.path.join(patient_dir, 'images')\n\n        for filename in os.listdir(images_dir):\n            image_path = os.path.join(images_dir, filename)\n            validation_data.append([image_path, patient, label])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_path = training_data[0][0]\nimage = Image.open(image_path)\nplt.imshow(image)\nplt.axis(\"off\")  # Hide axes\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torchvision.transforms as transforms\n\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((224, 224)),  \n        transforms.RandomRotation(degrees=5),  # Rotate image by ±5 degrees\n        transforms.RandomHorizontalFlip(),  # Random horizontal flip\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = LiverDiseaseDataset(training_data, transform=data_transforms['train'])\nval_dataset = LiverDiseaseDataset(validation_data, transform=data_transforms['val'])\ntest_dataset = LiverDiseaseDataset(testing_data, transform=data_transforms['test'])\n\n# Create Data Loaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SelfAttention(nn.Module):\n    def __init__(self, embed_dim, num_heads=8):\n        super(SelfAttention, self).__init__()\n        self.attn = nn.MultiheadAttention(embed_dim, num_heads)\n    \n    def forward(self, x):\n        # Flatten (Batch, Channels, Height * Width) -> (Height * Width, Batch, Channels)\n        B, C, H, W = x.shape\n        x = x.view(B, C, -1).permute(2, 0, 1)  # (HW, B, C)\n\n        attn_output, _ = self.attn(x, x, x)\n        attn_output = attn_output.permute(1, 2, 0).view(B, C, H, W)  # Reshape back\n\n        return attn_output + x.permute(1, 2, 0).view(B, C, H, W)  # Residual connection\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class AttentionDenseNet(nn.Module):\n    def __init__(self, num_classes=3):\n        super(AttentionDenseNet, self).__init__()\n        self.base_model = models.densenet121(pretrained=True)\n        self.base_model.classifier = nn.Identity()  # Remove the default classifier\n        \n        # Insert self-attention module after the last convolutional layer\n        self.attention = SelfAttention(embed_dim=1024, num_heads=8)  # 1024 channels in DenseNet\n        \n        self.classifier = nn.Linear(1024, num_classes)  # Final classification layer\n\n    def forward(self, x):\n        x = self.base_model.features(x)  # Extract features\n        x = self.attention(x)  # Apply self-attention\n        x = torch.nn.functional.adaptive_avg_pool2d(x, (1, 1))  # Global average pooling\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)  # Final classifier\n        return x\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = AttentionDenseNet(num_classes=num_classes).to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\n\n# Training loop remains the same\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x = torch.randn(1, 3, 224, 224).to(device)\n\n# Hook fn that handles tensor or tuple outputs\ndef forward_hook(module, inp, outp):\n    num_params = sum(p.numel() for p in module.parameters() if p.requires_grad)\n    # get shape from first tensor if tuple, else from tensor\n    if isinstance(outp, tuple):\n        shape = outp[0].shape\n    else:\n        shape = outp.shape\n    shape = tuple(shape)\n    print(f\"{module.__class__.__name__:<20} | Output shape: {str(shape):<20} | Params: {num_params}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = model.to(device)\n\n# Calculate and print the total number of trainable parameters\ntotal_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"✅ Total Trainable Parameters: {total_params}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x = torch.randn(1, 3, 224, 224).to(device)\ndef forward_hook(module, inp, outp):\n    num_params = sum(p.numel() for p in module.parameters() if p.requires_grad)\n    if isinstance(outp, tuple):\n        shape = outp[0].shape\n    else:\n        shape = outp.shape\n    shape_str = str(shape)\n    print(f\"{module.__class__.__name__:<20} | Output shape: {shape_str:<20} | Params: {num_params}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchsummary import summary\nsummary(model, input_size=(3, 224, 224))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.optim.lr_scheduler\n\n# Initialize scheduler\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n\nnum_epochs = 50\ntrain_losses, val_losses, train_acc, val_acc = [], [], [], []\n\nfor epoch in range(num_epochs):\n    for phase in ['train', 'val']:\n        if phase == 'train':\n            model.train()\n            dataloader = train_loader\n        else:\n            model.eval()\n            dataloader = val_loader\n\n        running_loss, correct = 0.0, 0\n\n        for inputs, labels in dataloader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n\n            with torch.set_grad_enabled(phase == 'train'):\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n\n            running_loss += loss.item()\n            correct += (outputs.argmax(1) == labels).sum().item()\n\n        epoch_loss = running_loss / len(dataloader)\n        epoch_acc = correct / len(dataloader.dataset)\n\n        if phase == 'train':\n            train_losses.append(epoch_loss)\n            train_acc.append(epoch_acc)\n            scheduler.step()  # Update learning rate\n\n        else:\n            val_losses.append(epoch_loss)\n            val_acc.append(epoch_acc)\n\n        print(f'Epoch {epoch+1} | {phase} Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}')\n\n# Plot results\nplt.figure(figsize=(10, 5))\nplt.plot(train_losses, label='Train Loss', marker='o')\nplt.plot(val_losses, label='Validation Loss', marker='o')\nplt.xlabel('Epochs'), plt.ylabel('Loss'), plt.title('Loss'), plt.legend()\nplt.show()\n\nplt.figure(figsize=(10, 5))\nplt.plot(train_acc, label='Train Acc', marker='o')\nplt.plot(val_acc, label='Validation Acc', marker='o')\nplt.xlabel('Epochs'), plt.ylabel('Accuracy'), plt.title('Accuracy'), plt.legend()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), \"densenet121_model.pth\")\nprint(\"Model saved successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import (\n    confusion_matrix, accuracy_score, classification_report, precision_recall_fscore_support\n)\n\n# Ensure model is in evaluation mode\nmodel.eval()\n\n# Store true and predicted labels\ny_true = []\ny_pred = []\n\n# Run model on test data\nwith torch.no_grad():\n    for inputs, labels in test_loader:  # Use your test data loader\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        outputs = model(inputs)\n        _, preds = torch.max(outputs, 1)\n\n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(preds.cpu().numpy())\n\n# Compute overall accuracy\naccuracy = accuracy_score(y_true, y_pred)\nprint(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n\n# Compute confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\n# Compute class-wise precision, recall, f1-score, and support\nprecision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred, average=None)\n\n# Compute specificity for each class\nspecificity = []\nfor i in range(len(class_names)):\n    tn = cm.sum() - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])  # True Negatives\n    fp = cm[:, i].sum() - cm[i, i]  # False Positives\n    specificity.append(tn / (tn + fp))\n\n# Compute overall precision, recall, and f1-score\noverall_precision, overall_recall, overall_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n\n# Compute overall specificity\noverall_specificity = np.mean(specificity)\n\n# Display class-wise metrics\nprint(\"\\nClass-wise Metrics:\")\nfor i, class_name in enumerate(class_names):\n    print(f\"{class_name}:\")\n    print(f\"  Precision: {precision[i]:.2f}\")\n    print(f\"  Recall: {recall[i]:.2f}\")\n    print(f\"  F1-Score: {f1[i]:.2f}\")\n    print(f\"  Specificity: {specificity[i]:.2f}\")\n\n# Print overall metrics\nprint(\"\\nOverall Metrics:\")\nprint(f\"  Precision: {overall_precision:.2f}\")\nprint(f\"  Recall: {overall_recall:.2f}\")\nprint(f\"  F1-Score: {overall_f1:.2f}\")\nprint(f\"  Specificity: {overall_specificity:.2f}\")\n\n# Print detailed classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true, y_pred, target_names=class_names, digits=2))\n\n# Plot confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}